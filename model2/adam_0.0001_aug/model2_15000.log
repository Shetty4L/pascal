I0710 13:36:32.665181  9938 caffe.cpp:185] Using GPUs 0
I0710 13:36:32.925928  9938 caffe.cpp:190] GPU 0: GRID K520
I0710 13:36:33.046103  9938 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.0001
display: 100
max_iter: 20000
lr_policy: "fixed"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "snapshots/model2"
solver_mode: GPU
device_id: 0
net: "model2_trainval.prototxt"
type: "Adam"
I0710 13:36:33.046278  9938 solver.cpp:91] Creating training net from net file: model2_trainval.prototxt
I0710 13:36:33.046907  9938 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0710 13:36:33.046938  9938 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0710 13:36:33.047093  9938 net.cpp:49] Initializing net from parameters: 
name: "Model2"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "../lmdb/mean_file.binaryproto"
  }
  data_param {
    source: "../lmdb/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "fc4"
  top: "fc4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 20
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TRAIN
  }
}
I0710 13:36:33.047246  9938 layer_factory.hpp:77] Creating layer data
I0710 13:36:33.047895  9938 net.cpp:91] Creating Layer data
I0710 13:36:33.047953  9938 net.cpp:399] data -> data
I0710 13:36:33.048003  9938 net.cpp:399] data -> label
I0710 13:36:33.048033  9938 data_transformer.cpp:25] Loading mean file from: ../lmdb/mean_file.binaryproto
I0710 13:36:33.048671  9945 db_lmdb.cpp:35] Opened lmdb ../lmdb/train_lmdb
I0710 13:36:33.061743  9938 data_layer.cpp:41] output data size: 256,3,128,128
I0710 13:36:33.159838  9938 net.cpp:141] Setting up data
I0710 13:36:33.159899  9938 net.cpp:148] Top shape: 256 3 128 128 (12582912)
I0710 13:36:33.159909  9938 net.cpp:148] Top shape: 256 (256)
I0710 13:36:33.159914  9938 net.cpp:156] Memory required for data: 50332672
I0710 13:36:33.159929  9938 layer_factory.hpp:77] Creating layer label_data_1_split
I0710 13:36:33.159953  9938 net.cpp:91] Creating Layer label_data_1_split
I0710 13:36:33.159965  9938 net.cpp:425] label_data_1_split <- label
I0710 13:36:33.159986  9938 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0710 13:36:33.160008  9938 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0710 13:36:33.160065  9938 net.cpp:141] Setting up label_data_1_split
I0710 13:36:33.160081  9938 net.cpp:148] Top shape: 256 (256)
I0710 13:36:33.160087  9938 net.cpp:148] Top shape: 256 (256)
I0710 13:36:33.160092  9938 net.cpp:156] Memory required for data: 50334720
I0710 13:36:33.160097  9938 layer_factory.hpp:77] Creating layer conv1
I0710 13:36:33.160127  9938 net.cpp:91] Creating Layer conv1
I0710 13:36:33.160140  9938 net.cpp:425] conv1 <- data
I0710 13:36:33.160150  9938 net.cpp:399] conv1 -> conv1
I0710 13:36:33.334589  9938 net.cpp:141] Setting up conv1
I0710 13:36:33.334637  9938 net.cpp:148] Top shape: 256 64 61 61 (60964864)
I0710 13:36:33.334645  9938 net.cpp:156] Memory required for data: 294194176
I0710 13:36:33.334676  9938 layer_factory.hpp:77] Creating layer relu1
I0710 13:36:33.334693  9938 net.cpp:91] Creating Layer relu1
I0710 13:36:33.334702  9938 net.cpp:425] relu1 <- conv1
I0710 13:36:33.334710  9938 net.cpp:386] relu1 -> conv1 (in-place)
I0710 13:36:33.334884  9938 net.cpp:141] Setting up relu1
I0710 13:36:33.334904  9938 net.cpp:148] Top shape: 256 64 61 61 (60964864)
I0710 13:36:33.334909  9938 net.cpp:156] Memory required for data: 538053632
I0710 13:36:33.334915  9938 layer_factory.hpp:77] Creating layer pool1
I0710 13:36:33.334929  9938 net.cpp:91] Creating Layer pool1
I0710 13:36:33.334934  9938 net.cpp:425] pool1 <- conv1
I0710 13:36:33.334942  9938 net.cpp:399] pool1 -> pool1
I0710 13:36:33.335002  9938 net.cpp:141] Setting up pool1
I0710 13:36:33.335019  9938 net.cpp:148] Top shape: 256 64 30 30 (14745600)
I0710 13:36:33.335024  9938 net.cpp:156] Memory required for data: 597036032
I0710 13:36:33.335029  9938 layer_factory.hpp:77] Creating layer conv2
I0710 13:36:33.335047  9938 net.cpp:91] Creating Layer conv2
I0710 13:36:33.335054  9938 net.cpp:425] conv2 <- pool1
I0710 13:36:33.335062  9938 net.cpp:399] conv2 -> conv2
I0710 13:36:33.337880  9938 net.cpp:141] Setting up conv2
I0710 13:36:33.337904  9938 net.cpp:148] Top shape: 256 128 13 13 (5537792)
I0710 13:36:33.337910  9938 net.cpp:156] Memory required for data: 619187200
I0710 13:36:33.337924  9938 layer_factory.hpp:77] Creating layer relu2
I0710 13:36:33.337934  9938 net.cpp:91] Creating Layer relu2
I0710 13:36:33.337939  9938 net.cpp:425] relu2 <- conv2
I0710 13:36:33.337947  9938 net.cpp:386] relu2 -> conv2 (in-place)
I0710 13:36:33.338186  9938 net.cpp:141] Setting up relu2
I0710 13:36:33.338207  9938 net.cpp:148] Top shape: 256 128 13 13 (5537792)
I0710 13:36:33.338212  9938 net.cpp:156] Memory required for data: 641338368
I0710 13:36:33.338218  9938 layer_factory.hpp:77] Creating layer conv3
I0710 13:36:33.338232  9938 net.cpp:91] Creating Layer conv3
I0710 13:36:33.338238  9938 net.cpp:425] conv3 <- conv2
I0710 13:36:33.338248  9938 net.cpp:399] conv3 -> conv3
I0710 13:36:33.341758  9938 net.cpp:141] Setting up conv3
I0710 13:36:33.341790  9938 net.cpp:148] Top shape: 256 256 11 11 (7929856)
I0710 13:36:33.341796  9938 net.cpp:156] Memory required for data: 673057792
I0710 13:36:33.341811  9938 layer_factory.hpp:77] Creating layer relu3
I0710 13:36:33.341825  9938 net.cpp:91] Creating Layer relu3
I0710 13:36:33.341830  9938 net.cpp:425] relu3 <- conv3
I0710 13:36:33.341869  9938 net.cpp:386] relu3 -> conv3 (in-place)
I0710 13:36:33.342116  9938 net.cpp:141] Setting up relu3
I0710 13:36:33.342138  9938 net.cpp:148] Top shape: 256 256 11 11 (7929856)
I0710 13:36:33.342142  9938 net.cpp:156] Memory required for data: 704777216
I0710 13:36:33.342149  9938 layer_factory.hpp:77] Creating layer pool3
I0710 13:36:33.342159  9938 net.cpp:91] Creating Layer pool3
I0710 13:36:33.342164  9938 net.cpp:425] pool3 <- conv3
I0710 13:36:33.342175  9938 net.cpp:399] pool3 -> pool3
I0710 13:36:33.342229  9938 net.cpp:141] Setting up pool3
I0710 13:36:33.342247  9938 net.cpp:148] Top shape: 256 256 5 5 (1638400)
I0710 13:36:33.342252  9938 net.cpp:156] Memory required for data: 711330816
I0710 13:36:33.342257  9938 layer_factory.hpp:77] Creating layer fc4
I0710 13:36:33.342270  9938 net.cpp:91] Creating Layer fc4
I0710 13:36:33.342285  9938 net.cpp:425] fc4 <- pool3
I0710 13:36:33.342296  9938 net.cpp:399] fc4 -> fc4
I0710 13:36:33.405683  9938 net.cpp:141] Setting up fc4
I0710 13:36:33.405738  9938 net.cpp:148] Top shape: 256 1024 (262144)
I0710 13:36:33.405747  9938 net.cpp:156] Memory required for data: 712379392
I0710 13:36:33.405764  9938 layer_factory.hpp:77] Creating layer relu4
I0710 13:36:33.405784  9938 net.cpp:91] Creating Layer relu4
I0710 13:36:33.405792  9938 net.cpp:425] relu4 <- fc4
I0710 13:36:33.405804  9938 net.cpp:386] relu4 -> fc4 (in-place)
I0710 13:36:33.406059  9938 net.cpp:141] Setting up relu4
I0710 13:36:33.406081  9938 net.cpp:148] Top shape: 256 1024 (262144)
I0710 13:36:33.406086  9938 net.cpp:156] Memory required for data: 713427968
I0710 13:36:33.406091  9938 layer_factory.hpp:77] Creating layer dropout4
I0710 13:36:33.406107  9938 net.cpp:91] Creating Layer dropout4
I0710 13:36:33.406112  9938 net.cpp:425] dropout4 <- fc4
I0710 13:36:33.406121  9938 net.cpp:386] dropout4 -> fc4 (in-place)
I0710 13:36:33.406165  9938 net.cpp:141] Setting up dropout4
I0710 13:36:33.406182  9938 net.cpp:148] Top shape: 256 1024 (262144)
I0710 13:36:33.406186  9938 net.cpp:156] Memory required for data: 714476544
I0710 13:36:33.406191  9938 layer_factory.hpp:77] Creating layer fc5
I0710 13:36:33.406208  9938 net.cpp:91] Creating Layer fc5
I0710 13:36:33.406219  9938 net.cpp:425] fc5 <- fc4
I0710 13:36:33.406230  9938 net.cpp:399] fc5 -> fc5
I0710 13:36:33.406522  9938 net.cpp:141] Setting up fc5
I0710 13:36:33.406545  9938 net.cpp:148] Top shape: 256 20 (5120)
I0710 13:36:33.406551  9938 net.cpp:156] Memory required for data: 714497024
I0710 13:36:33.406569  9938 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0710 13:36:33.406586  9938 net.cpp:91] Creating Layer fc5_fc5_0_split
I0710 13:36:33.406592  9938 net.cpp:425] fc5_fc5_0_split <- fc5
I0710 13:36:33.406600  9938 net.cpp:399] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0710 13:36:33.406610  9938 net.cpp:399] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0710 13:36:33.406653  9938 net.cpp:141] Setting up fc5_fc5_0_split
I0710 13:36:33.406669  9938 net.cpp:148] Top shape: 256 20 (5120)
I0710 13:36:33.406675  9938 net.cpp:148] Top shape: 256 20 (5120)
I0710 13:36:33.406679  9938 net.cpp:156] Memory required for data: 714537984
I0710 13:36:33.406684  9938 layer_factory.hpp:77] Creating layer loss
I0710 13:36:33.406697  9938 net.cpp:91] Creating Layer loss
I0710 13:36:33.406702  9938 net.cpp:425] loss <- fc5_fc5_0_split_0
I0710 13:36:33.406710  9938 net.cpp:425] loss <- label_data_1_split_0
I0710 13:36:33.406721  9938 net.cpp:399] loss -> loss
I0710 13:36:33.406746  9938 layer_factory.hpp:77] Creating layer loss
I0710 13:36:33.407169  9938 net.cpp:141] Setting up loss
I0710 13:36:33.407192  9938 net.cpp:148] Top shape: (1)
I0710 13:36:33.407199  9938 net.cpp:151]     with loss weight 1
I0710 13:36:33.407239  9938 net.cpp:156] Memory required for data: 714537988
I0710 13:36:33.407246  9938 layer_factory.hpp:77] Creating layer accuracy
I0710 13:36:33.407266  9938 net.cpp:91] Creating Layer accuracy
I0710 13:36:33.407274  9938 net.cpp:425] accuracy <- fc5_fc5_0_split_1
I0710 13:36:33.407281  9938 net.cpp:425] accuracy <- label_data_1_split_1
I0710 13:36:33.407320  9938 net.cpp:399] accuracy -> accuracy
I0710 13:36:33.407341  9938 net.cpp:141] Setting up accuracy
I0710 13:36:33.407356  9938 net.cpp:148] Top shape: (1)
I0710 13:36:33.407359  9938 net.cpp:156] Memory required for data: 714537992
I0710 13:36:33.407364  9938 net.cpp:219] accuracy does not need backward computation.
I0710 13:36:33.407371  9938 net.cpp:217] loss needs backward computation.
I0710 13:36:33.407376  9938 net.cpp:217] fc5_fc5_0_split needs backward computation.
I0710 13:36:33.407380  9938 net.cpp:217] fc5 needs backward computation.
I0710 13:36:33.407384  9938 net.cpp:217] dropout4 needs backward computation.
I0710 13:36:33.407389  9938 net.cpp:217] relu4 needs backward computation.
I0710 13:36:33.407393  9938 net.cpp:217] fc4 needs backward computation.
I0710 13:36:33.407397  9938 net.cpp:217] pool3 needs backward computation.
I0710 13:36:33.407402  9938 net.cpp:217] relu3 needs backward computation.
I0710 13:36:33.407410  9938 net.cpp:217] conv3 needs backward computation.
I0710 13:36:33.407418  9938 net.cpp:217] relu2 needs backward computation.
I0710 13:36:33.407423  9938 net.cpp:217] conv2 needs backward computation.
I0710 13:36:33.407428  9938 net.cpp:217] pool1 needs backward computation.
I0710 13:36:33.407431  9938 net.cpp:217] relu1 needs backward computation.
I0710 13:36:33.407436  9938 net.cpp:217] conv1 needs backward computation.
I0710 13:36:33.407441  9938 net.cpp:219] label_data_1_split does not need backward computation.
I0710 13:36:33.407446  9938 net.cpp:219] data does not need backward computation.
I0710 13:36:33.407450  9938 net.cpp:261] This network produces output accuracy
I0710 13:36:33.407456  9938 net.cpp:261] This network produces output loss
I0710 13:36:33.407477  9938 net.cpp:274] Network initialization done.
I0710 13:36:33.408121  9938 solver.cpp:181] Creating test net (#0) specified by net file: model2_trainval.prototxt
I0710 13:36:33.408172  9938 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0710 13:36:33.408210  9938 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy
I0710 13:36:33.408360  9938 net.cpp:49] Initializing net from parameters: 
name: "Model2"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_file: "../lmdb/mean_file.binaryproto"
  }
  data_param {
    source: "../lmdb/val_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "fc4"
  top: "fc4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 20
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0710 13:36:33.408485  9938 layer_factory.hpp:77] Creating layer data
I0710 13:36:33.408648  9938 net.cpp:91] Creating Layer data
I0710 13:36:33.408660  9938 net.cpp:399] data -> data
I0710 13:36:33.408673  9938 net.cpp:399] data -> label
I0710 13:36:33.408682  9938 data_transformer.cpp:25] Loading mean file from: ../lmdb/mean_file.binaryproto
I0710 13:36:33.409361  9947 db_lmdb.cpp:35] Opened lmdb ../lmdb/val_lmdb
I0710 13:36:33.409559  9938 data_layer.cpp:41] output data size: 128,3,128,128
I0710 13:36:33.464278  9938 net.cpp:141] Setting up data
I0710 13:36:33.464329  9938 net.cpp:148] Top shape: 128 3 128 128 (6291456)
I0710 13:36:33.464336  9938 net.cpp:148] Top shape: 128 (128)
I0710 13:36:33.464341  9938 net.cpp:156] Memory required for data: 25166336
I0710 13:36:33.464354  9938 layer_factory.hpp:77] Creating layer label_data_1_split
I0710 13:36:33.464376  9938 net.cpp:91] Creating Layer label_data_1_split
I0710 13:36:33.464385  9938 net.cpp:425] label_data_1_split <- label
I0710 13:36:33.464397  9938 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0710 13:36:33.464414  9938 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0710 13:36:33.464540  9938 net.cpp:141] Setting up label_data_1_split
I0710 13:36:33.464556  9938 net.cpp:148] Top shape: 128 (128)
I0710 13:36:33.464563  9938 net.cpp:148] Top shape: 128 (128)
I0710 13:36:33.464567  9938 net.cpp:156] Memory required for data: 25167360
I0710 13:36:33.464572  9938 layer_factory.hpp:77] Creating layer conv1
I0710 13:36:33.464597  9938 net.cpp:91] Creating Layer conv1
I0710 13:36:33.464608  9938 net.cpp:425] conv1 <- data
I0710 13:36:33.464619  9938 net.cpp:399] conv1 -> conv1
I0710 13:36:33.470288  9938 net.cpp:141] Setting up conv1
I0710 13:36:33.470316  9938 net.cpp:148] Top shape: 128 64 61 61 (30482432)
I0710 13:36:33.470322  9938 net.cpp:156] Memory required for data: 147097088
I0710 13:36:33.470338  9938 layer_factory.hpp:77] Creating layer relu1
I0710 13:36:33.470350  9938 net.cpp:91] Creating Layer relu1
I0710 13:36:33.470355  9938 net.cpp:425] relu1 <- conv1
I0710 13:36:33.470365  9938 net.cpp:386] relu1 -> conv1 (in-place)
I0710 13:36:33.470525  9938 net.cpp:141] Setting up relu1
I0710 13:36:33.470544  9938 net.cpp:148] Top shape: 128 64 61 61 (30482432)
I0710 13:36:33.470549  9938 net.cpp:156] Memory required for data: 269026816
I0710 13:36:33.470556  9938 layer_factory.hpp:77] Creating layer pool1
I0710 13:36:33.470568  9938 net.cpp:91] Creating Layer pool1
I0710 13:36:33.470574  9938 net.cpp:425] pool1 <- conv1
I0710 13:36:33.470582  9938 net.cpp:399] pool1 -> pool1
I0710 13:36:33.470635  9938 net.cpp:141] Setting up pool1
I0710 13:36:33.470651  9938 net.cpp:148] Top shape: 128 64 30 30 (7372800)
I0710 13:36:33.470656  9938 net.cpp:156] Memory required for data: 298518016
I0710 13:36:33.470661  9938 layer_factory.hpp:77] Creating layer conv2
I0710 13:36:33.470676  9938 net.cpp:91] Creating Layer conv2
I0710 13:36:33.470708  9938 net.cpp:425] conv2 <- pool1
I0710 13:36:33.470721  9938 net.cpp:399] conv2 -> conv2
I0710 13:36:33.473763  9938 net.cpp:141] Setting up conv2
I0710 13:36:33.473788  9938 net.cpp:148] Top shape: 128 128 13 13 (2768896)
I0710 13:36:33.473793  9938 net.cpp:156] Memory required for data: 309593600
I0710 13:36:33.473806  9938 layer_factory.hpp:77] Creating layer relu2
I0710 13:36:33.473816  9938 net.cpp:91] Creating Layer relu2
I0710 13:36:33.473821  9938 net.cpp:425] relu2 <- conv2
I0710 13:36:33.473829  9938 net.cpp:386] relu2 -> conv2 (in-place)
I0710 13:36:33.474097  9938 net.cpp:141] Setting up relu2
I0710 13:36:33.474119  9938 net.cpp:148] Top shape: 128 128 13 13 (2768896)
I0710 13:36:33.474124  9938 net.cpp:156] Memory required for data: 320669184
I0710 13:36:33.474129  9938 layer_factory.hpp:77] Creating layer conv3
I0710 13:36:33.474144  9938 net.cpp:91] Creating Layer conv3
I0710 13:36:33.474150  9938 net.cpp:425] conv3 <- conv2
I0710 13:36:33.474159  9938 net.cpp:399] conv3 -> conv3
I0710 13:36:33.477793  9938 net.cpp:141] Setting up conv3
I0710 13:36:33.477824  9938 net.cpp:148] Top shape: 128 256 11 11 (3964928)
I0710 13:36:33.477830  9938 net.cpp:156] Memory required for data: 336528896
I0710 13:36:33.477849  9938 layer_factory.hpp:77] Creating layer relu3
I0710 13:36:33.477862  9938 net.cpp:91] Creating Layer relu3
I0710 13:36:33.477869  9938 net.cpp:425] relu3 <- conv3
I0710 13:36:33.477875  9938 net.cpp:386] relu3 -> conv3 (in-place)
I0710 13:36:33.478123  9938 net.cpp:141] Setting up relu3
I0710 13:36:33.478143  9938 net.cpp:148] Top shape: 128 256 11 11 (3964928)
I0710 13:36:33.478149  9938 net.cpp:156] Memory required for data: 352388608
I0710 13:36:33.478154  9938 layer_factory.hpp:77] Creating layer pool3
I0710 13:36:33.478164  9938 net.cpp:91] Creating Layer pool3
I0710 13:36:33.478169  9938 net.cpp:425] pool3 <- conv3
I0710 13:36:33.478180  9938 net.cpp:399] pool3 -> pool3
I0710 13:36:33.478240  9938 net.cpp:141] Setting up pool3
I0710 13:36:33.478256  9938 net.cpp:148] Top shape: 128 256 5 5 (819200)
I0710 13:36:33.478261  9938 net.cpp:156] Memory required for data: 355665408
I0710 13:36:33.478266  9938 layer_factory.hpp:77] Creating layer fc4
I0710 13:36:33.478281  9938 net.cpp:91] Creating Layer fc4
I0710 13:36:33.478286  9938 net.cpp:425] fc4 <- pool3
I0710 13:36:33.478293  9938 net.cpp:399] fc4 -> fc4
I0710 13:36:33.541066  9938 net.cpp:141] Setting up fc4
I0710 13:36:33.541112  9938 net.cpp:148] Top shape: 128 1024 (131072)
I0710 13:36:33.541118  9938 net.cpp:156] Memory required for data: 356189696
I0710 13:36:33.541136  9938 layer_factory.hpp:77] Creating layer relu4
I0710 13:36:33.541152  9938 net.cpp:91] Creating Layer relu4
I0710 13:36:33.541159  9938 net.cpp:425] relu4 <- fc4
I0710 13:36:33.541170  9938 net.cpp:386] relu4 -> fc4 (in-place)
I0710 13:36:33.541618  9938 net.cpp:141] Setting up relu4
I0710 13:36:33.541640  9938 net.cpp:148] Top shape: 128 1024 (131072)
I0710 13:36:33.541645  9938 net.cpp:156] Memory required for data: 356713984
I0710 13:36:33.541651  9938 layer_factory.hpp:77] Creating layer dropout4
I0710 13:36:33.541661  9938 net.cpp:91] Creating Layer dropout4
I0710 13:36:33.541666  9938 net.cpp:425] dropout4 <- fc4
I0710 13:36:33.541676  9938 net.cpp:386] dropout4 -> fc4 (in-place)
I0710 13:36:33.541707  9938 net.cpp:141] Setting up dropout4
I0710 13:36:33.541725  9938 net.cpp:148] Top shape: 128 1024 (131072)
I0710 13:36:33.541731  9938 net.cpp:156] Memory required for data: 357238272
I0710 13:36:33.541736  9938 layer_factory.hpp:77] Creating layer fc5
I0710 13:36:33.541746  9938 net.cpp:91] Creating Layer fc5
I0710 13:36:33.541751  9938 net.cpp:425] fc5 <- fc4
I0710 13:36:33.541761  9938 net.cpp:399] fc5 -> fc5
I0710 13:36:33.542079  9938 net.cpp:141] Setting up fc5
I0710 13:36:33.542098  9938 net.cpp:148] Top shape: 128 20 (2560)
I0710 13:36:33.542104  9938 net.cpp:156] Memory required for data: 357248512
I0710 13:36:33.542119  9938 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0710 13:36:33.542142  9938 net.cpp:91] Creating Layer fc5_fc5_0_split
I0710 13:36:33.542168  9938 net.cpp:425] fc5_fc5_0_split <- fc5
I0710 13:36:33.542176  9938 net.cpp:399] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0710 13:36:33.542188  9938 net.cpp:399] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0710 13:36:33.542230  9938 net.cpp:141] Setting up fc5_fc5_0_split
I0710 13:36:33.542246  9938 net.cpp:148] Top shape: 128 20 (2560)
I0710 13:36:33.542253  9938 net.cpp:148] Top shape: 128 20 (2560)
I0710 13:36:33.542256  9938 net.cpp:156] Memory required for data: 357268992
I0710 13:36:33.542261  9938 layer_factory.hpp:77] Creating layer loss
I0710 13:36:33.542270  9938 net.cpp:91] Creating Layer loss
I0710 13:36:33.542274  9938 net.cpp:425] loss <- fc5_fc5_0_split_0
I0710 13:36:33.542280  9938 net.cpp:425] loss <- label_data_1_split_0
I0710 13:36:33.542292  9938 net.cpp:399] loss -> loss
I0710 13:36:33.542309  9938 layer_factory.hpp:77] Creating layer loss
I0710 13:36:33.542577  9938 net.cpp:141] Setting up loss
I0710 13:36:33.542596  9938 net.cpp:148] Top shape: (1)
I0710 13:36:33.542601  9938 net.cpp:151]     with loss weight 1
I0710 13:36:33.542618  9938 net.cpp:156] Memory required for data: 357268996
I0710 13:36:33.542623  9938 layer_factory.hpp:77] Creating layer accuracy
I0710 13:36:33.542641  9938 net.cpp:91] Creating Layer accuracy
I0710 13:36:33.542654  9938 net.cpp:425] accuracy <- fc5_fc5_0_split_1
I0710 13:36:33.542660  9938 net.cpp:425] accuracy <- label_data_1_split_1
I0710 13:36:33.542667  9938 net.cpp:399] accuracy -> accuracy
I0710 13:36:33.542681  9938 net.cpp:141] Setting up accuracy
I0710 13:36:33.542690  9938 net.cpp:148] Top shape: (1)
I0710 13:36:33.542695  9938 net.cpp:156] Memory required for data: 357269000
I0710 13:36:33.542700  9938 net.cpp:219] accuracy does not need backward computation.
I0710 13:36:33.542704  9938 net.cpp:217] loss needs backward computation.
I0710 13:36:33.542709  9938 net.cpp:217] fc5_fc5_0_split needs backward computation.
I0710 13:36:33.542714  9938 net.cpp:217] fc5 needs backward computation.
I0710 13:36:33.542719  9938 net.cpp:217] dropout4 needs backward computation.
I0710 13:36:33.542723  9938 net.cpp:217] relu4 needs backward computation.
I0710 13:36:33.542731  9938 net.cpp:217] fc4 needs backward computation.
I0710 13:36:33.542738  9938 net.cpp:217] pool3 needs backward computation.
I0710 13:36:33.542747  9938 net.cpp:217] relu3 needs backward computation.
I0710 13:36:33.542752  9938 net.cpp:217] conv3 needs backward computation.
I0710 13:36:33.542757  9938 net.cpp:217] relu2 needs backward computation.
I0710 13:36:33.542762  9938 net.cpp:217] conv2 needs backward computation.
I0710 13:36:33.542767  9938 net.cpp:217] pool1 needs backward computation.
I0710 13:36:33.542771  9938 net.cpp:217] relu1 needs backward computation.
I0710 13:36:33.542775  9938 net.cpp:217] conv1 needs backward computation.
I0710 13:36:33.542780  9938 net.cpp:219] label_data_1_split does not need backward computation.
I0710 13:36:33.542786  9938 net.cpp:219] data does not need backward computation.
I0710 13:36:33.542790  9938 net.cpp:261] This network produces output accuracy
I0710 13:36:33.542794  9938 net.cpp:261] This network produces output loss
I0710 13:36:33.542812  9938 net.cpp:274] Network initialization done.
I0710 13:36:33.542943  9938 solver.cpp:60] Solver scaffolding done.
I0710 13:36:33.543489  9938 caffe.cpp:209] Resuming from snapshots/model2_iter_10000.solverstate
I0710 13:36:33.706568  9938 sgd_solver.cpp:318] SGDSolver: restoring history
I0710 13:36:33.749927  9938 caffe.cpp:219] Starting Optimization
I0710 13:36:33.749981  9938 solver.cpp:279] Solving Model2
I0710 13:36:33.749989  9938 solver.cpp:280] Learning Rate Policy: fixed
I0710 13:36:33.750813  9938 solver.cpp:337] Iteration 10000, Testing net (#0)
I0710 13:36:39.211155  9938 solver.cpp:404]     Test net output #0: accuracy = 0.705859
I0710 13:36:39.211217  9938 solver.cpp:404]     Test net output #1: loss = 1.62362 (* 1 = 1.62362 loss)
I0710 13:36:39.335681  9938 solver.cpp:228] Iteration 10000, loss = 0.118872
I0710 13:36:39.335737  9938 solver.cpp:244]     Train net output #0: accuracy = 0.960938
I0710 13:36:39.335786  9938 solver.cpp:244]     Train net output #1: loss = 0.118872 (* 1 = 0.118872 loss)
I0710 13:36:39.335800  9938 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0710 13:37:11.395771  9938 solver.cpp:228] Iteration 10100, loss = 0.12053
I0710 13:37:11.395895  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:37:11.395915  9938 solver.cpp:244]     Train net output #1: loss = 0.12053 (* 1 = 0.12053 loss)
I0710 13:37:11.395922  9938 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0710 13:37:43.107090  9938 solver.cpp:228] Iteration 10200, loss = 0.156186
I0710 13:37:43.107229  9938 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0710 13:37:43.107246  9938 solver.cpp:244]     Train net output #1: loss = 0.156186 (* 1 = 0.156186 loss)
I0710 13:37:43.107255  9938 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0710 13:38:14.820475  9938 solver.cpp:228] Iteration 10300, loss = 0.104416
I0710 13:38:14.820607  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:38:14.820626  9938 solver.cpp:244]     Train net output #1: loss = 0.104416 (* 1 = 0.104416 loss)
I0710 13:38:14.820634  9938 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0710 13:38:46.536365  9938 solver.cpp:228] Iteration 10400, loss = 0.145476
I0710 13:38:46.536501  9938 solver.cpp:244]     Train net output #0: accuracy = 0.945312
I0710 13:38:46.536520  9938 solver.cpp:244]     Train net output #1: loss = 0.145476 (* 1 = 0.145476 loss)
I0710 13:38:46.536528  9938 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0710 13:39:18.245311  9938 solver.cpp:228] Iteration 10500, loss = 0.113665
I0710 13:39:18.245460  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:39:18.245478  9938 solver.cpp:244]     Train net output #1: loss = 0.113665 (* 1 = 0.113665 loss)
I0710 13:39:18.245486  9938 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0710 13:39:49.954619  9938 solver.cpp:228] Iteration 10600, loss = 0.154996
I0710 13:39:49.954761  9938 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0710 13:39:49.954778  9938 solver.cpp:244]     Train net output #1: loss = 0.154996 (* 1 = 0.154996 loss)
I0710 13:39:49.954787  9938 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0710 13:40:21.664003  9938 solver.cpp:228] Iteration 10700, loss = 0.239397
I0710 13:40:21.664090  9938 solver.cpp:244]     Train net output #0: accuracy = 0.925781
I0710 13:40:21.664108  9938 solver.cpp:244]     Train net output #1: loss = 0.239397 (* 1 = 0.239397 loss)
I0710 13:40:21.664116  9938 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0710 13:40:53.374673  9938 solver.cpp:228] Iteration 10800, loss = 0.112703
I0710 13:40:53.374807  9938 solver.cpp:244]     Train net output #0: accuracy = 0.976562
I0710 13:40:53.374826  9938 solver.cpp:244]     Train net output #1: loss = 0.112703 (* 1 = 0.112703 loss)
I0710 13:40:53.374835  9938 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0710 13:41:25.091904  9938 solver.cpp:228] Iteration 10900, loss = 0.136711
I0710 13:41:25.092036  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:41:25.092052  9938 solver.cpp:244]     Train net output #1: loss = 0.136711 (* 1 = 0.136711 loss)
I0710 13:41:25.092061  9938 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0710 13:41:56.485222  9938 solver.cpp:337] Iteration 11000, Testing net (#0)
I0710 13:42:02.154633  9938 solver.cpp:404]     Test net output #0: accuracy = 0.711563
I0710 13:42:02.154692  9938 solver.cpp:404]     Test net output #1: loss = 1.64203 (* 1 = 1.64203 loss)
I0710 13:42:02.264619  9938 solver.cpp:228] Iteration 11000, loss = 0.126312
I0710 13:42:02.264683  9938 solver.cpp:244]     Train net output #0: accuracy = 0.960938
I0710 13:42:02.264699  9938 solver.cpp:244]     Train net output #1: loss = 0.126312 (* 1 = 0.126312 loss)
I0710 13:42:02.264708  9938 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0710 13:42:34.517894  9938 solver.cpp:228] Iteration 11100, loss = 0.112205
I0710 13:42:34.518060  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:42:34.518079  9938 solver.cpp:244]     Train net output #1: loss = 0.112205 (* 1 = 0.112205 loss)
I0710 13:42:34.518087  9938 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0710 13:43:06.683238  9938 solver.cpp:228] Iteration 11200, loss = 0.106472
I0710 13:43:06.683364  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 13:43:06.683382  9938 solver.cpp:244]     Train net output #1: loss = 0.106472 (* 1 = 0.106472 loss)
I0710 13:43:06.683392  9938 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0710 13:43:38.390933  9938 solver.cpp:228] Iteration 11300, loss = 0.106932
I0710 13:43:38.391027  9938 solver.cpp:244]     Train net output #0: accuracy = 0.949219
I0710 13:43:38.391043  9938 solver.cpp:244]     Train net output #1: loss = 0.106932 (* 1 = 0.106932 loss)
I0710 13:43:38.391052  9938 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0710 13:44:10.103204  9938 solver.cpp:228] Iteration 11400, loss = 0.108892
I0710 13:44:10.103294  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:44:10.103312  9938 solver.cpp:244]     Train net output #1: loss = 0.108892 (* 1 = 0.108892 loss)
I0710 13:44:10.103319  9938 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0710 13:44:41.815614  9938 solver.cpp:228] Iteration 11500, loss = 0.0895633
I0710 13:44:41.815699  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:44:41.815716  9938 solver.cpp:244]     Train net output #1: loss = 0.0895633 (* 1 = 0.0895633 loss)
I0710 13:44:41.815724  9938 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0710 13:45:13.526171  9938 solver.cpp:228] Iteration 11600, loss = 0.0711591
I0710 13:45:13.526257  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:45:13.526273  9938 solver.cpp:244]     Train net output #1: loss = 0.0711591 (* 1 = 0.0711591 loss)
I0710 13:45:13.526281  9938 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0710 13:45:45.242022  9938 solver.cpp:228] Iteration 11700, loss = 0.0856729
I0710 13:45:45.242110  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 13:45:45.242127  9938 solver.cpp:244]     Train net output #1: loss = 0.0856729 (* 1 = 0.0856729 loss)
I0710 13:45:45.242136  9938 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0710 13:46:16.951894  9938 solver.cpp:228] Iteration 11800, loss = 0.0777131
I0710 13:46:16.951982  9938 solver.cpp:244]     Train net output #0: accuracy = 0.976562
I0710 13:46:16.951997  9938 solver.cpp:244]     Train net output #1: loss = 0.0777131 (* 1 = 0.0777131 loss)
I0710 13:46:16.952006  9938 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0710 13:46:48.661065  9938 solver.cpp:228] Iteration 11900, loss = 0.111725
I0710 13:46:48.661154  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:46:48.661170  9938 solver.cpp:244]     Train net output #1: loss = 0.111725 (* 1 = 0.111725 loss)
I0710 13:46:48.661180  9938 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0710 13:47:20.055626  9938 solver.cpp:337] Iteration 12000, Testing net (#0)
I0710 13:47:25.714776  9938 solver.cpp:404]     Test net output #0: accuracy = 0.714922
I0710 13:47:25.714836  9938 solver.cpp:404]     Test net output #1: loss = 1.62001 (* 1 = 1.62001 loss)
I0710 13:47:25.823982  9938 solver.cpp:228] Iteration 12000, loss = 0.0769487
I0710 13:47:25.824040  9938 solver.cpp:244]     Train net output #0: accuracy = 0.976562
I0710 13:47:25.824056  9938 solver.cpp:244]     Train net output #1: loss = 0.0769487 (* 1 = 0.0769487 loss)
I0710 13:47:25.824065  9938 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0710 13:47:58.060968  9938 solver.cpp:228] Iteration 12100, loss = 0.1208
I0710 13:47:58.061058  9938 solver.cpp:244]     Train net output #0: accuracy = 0.945312
I0710 13:47:58.061074  9938 solver.cpp:244]     Train net output #1: loss = 0.1208 (* 1 = 0.1208 loss)
I0710 13:47:58.061082  9938 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0710 13:48:29.999238  9938 solver.cpp:228] Iteration 12200, loss = 0.067424
I0710 13:48:29.999364  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:48:29.999382  9938 solver.cpp:244]     Train net output #1: loss = 0.067424 (* 1 = 0.067424 loss)
I0710 13:48:29.999392  9938 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0710 13:49:01.710631  9938 solver.cpp:228] Iteration 12300, loss = 0.159987
I0710 13:49:01.710777  9938 solver.cpp:244]     Train net output #0: accuracy = 0.941406
I0710 13:49:01.710794  9938 solver.cpp:244]     Train net output #1: loss = 0.159987 (* 1 = 0.159987 loss)
I0710 13:49:01.710803  9938 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0710 13:49:33.424556  9938 solver.cpp:228] Iteration 12400, loss = 0.0570857
I0710 13:49:33.424649  9938 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0710 13:49:33.424666  9938 solver.cpp:244]     Train net output #1: loss = 0.0570857 (* 1 = 0.0570857 loss)
I0710 13:49:33.424674  9938 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0710 13:50:05.132099  9938 solver.cpp:228] Iteration 12500, loss = 0.070886
I0710 13:50:05.132186  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:50:05.132202  9938 solver.cpp:244]     Train net output #1: loss = 0.070886 (* 1 = 0.070886 loss)
I0710 13:50:05.132211  9938 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0710 13:50:36.842056  9938 solver.cpp:228] Iteration 12600, loss = 0.120611
I0710 13:50:36.842149  9938 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0710 13:50:36.842166  9938 solver.cpp:244]     Train net output #1: loss = 0.120611 (* 1 = 0.120611 loss)
I0710 13:50:36.842175  9938 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0710 13:51:08.549873  9938 solver.cpp:228] Iteration 12700, loss = 0.0897361
I0710 13:51:08.549968  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:51:08.549984  9938 solver.cpp:244]     Train net output #1: loss = 0.0897361 (* 1 = 0.0897361 loss)
I0710 13:51:08.549993  9938 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0710 13:51:40.265050  9938 solver.cpp:228] Iteration 12800, loss = 0.0872044
I0710 13:51:40.265139  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 13:51:40.265156  9938 solver.cpp:244]     Train net output #1: loss = 0.0872044 (* 1 = 0.0872044 loss)
I0710 13:51:40.265164  9938 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0710 13:52:11.976654  9938 solver.cpp:228] Iteration 12900, loss = 0.144521
I0710 13:52:11.976737  9938 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0710 13:52:11.976753  9938 solver.cpp:244]     Train net output #1: loss = 0.144521 (* 1 = 0.144521 loss)
I0710 13:52:11.976763  9938 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0710 13:52:43.369324  9938 solver.cpp:337] Iteration 13000, Testing net (#0)
I0710 13:52:49.028364  9938 solver.cpp:404]     Test net output #0: accuracy = 0.707031
I0710 13:52:49.028424  9938 solver.cpp:404]     Test net output #1: loss = 1.87793 (* 1 = 1.87793 loss)
I0710 13:52:49.137256  9938 solver.cpp:228] Iteration 13000, loss = 0.105621
I0710 13:52:49.137315  9938 solver.cpp:244]     Train net output #0: accuracy = 0.949219
I0710 13:52:49.137329  9938 solver.cpp:244]     Train net output #1: loss = 0.105621 (* 1 = 0.105621 loss)
I0710 13:52:49.137337  9938 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0710 13:53:21.325620  9938 solver.cpp:228] Iteration 13100, loss = 0.129127
I0710 13:53:21.325736  9938 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0710 13:53:21.325752  9938 solver.cpp:244]     Train net output #1: loss = 0.129127 (* 1 = 0.129127 loss)
I0710 13:53:21.325762  9938 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0710 13:53:53.036152  9938 solver.cpp:228] Iteration 13200, loss = 0.0679
I0710 13:53:53.036245  9938 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0710 13:53:53.036262  9938 solver.cpp:244]     Train net output #1: loss = 0.0679 (* 1 = 0.0679 loss)
I0710 13:53:53.036270  9938 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0710 13:54:24.746485  9938 solver.cpp:228] Iteration 13300, loss = 0.108156
I0710 13:54:24.746672  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:54:24.746691  9938 solver.cpp:244]     Train net output #1: loss = 0.108156 (* 1 = 0.108156 loss)
I0710 13:54:24.746700  9938 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0710 13:54:56.455345  9938 solver.cpp:228] Iteration 13400, loss = 0.108431
I0710 13:54:56.455492  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:54:56.455509  9938 solver.cpp:244]     Train net output #1: loss = 0.108431 (* 1 = 0.108431 loss)
I0710 13:54:56.455518  9938 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0710 13:55:28.168334  9938 solver.cpp:228] Iteration 13500, loss = 0.0808862
I0710 13:55:28.168421  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:55:28.168437  9938 solver.cpp:244]     Train net output #1: loss = 0.0808862 (* 1 = 0.0808862 loss)
I0710 13:55:28.168445  9938 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0710 13:55:59.872592  9938 solver.cpp:228] Iteration 13600, loss = 0.0925104
I0710 13:55:59.872707  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 13:55:59.872725  9938 solver.cpp:244]     Train net output #1: loss = 0.0925104 (* 1 = 0.0925104 loss)
I0710 13:55:59.872733  9938 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0710 13:56:31.583084  9938 solver.cpp:228] Iteration 13700, loss = 0.0987938
I0710 13:56:31.583205  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:56:31.583223  9938 solver.cpp:244]     Train net output #1: loss = 0.0987938 (* 1 = 0.0987938 loss)
I0710 13:56:31.583231  9938 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0710 13:57:03.291959  9938 solver.cpp:228] Iteration 13800, loss = 0.140929
I0710 13:57:03.292049  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:57:03.292064  9938 solver.cpp:244]     Train net output #1: loss = 0.140929 (* 1 = 0.140929 loss)
I0710 13:57:03.292073  9938 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0710 13:57:35.002075  9938 solver.cpp:228] Iteration 13900, loss = 0.082243
I0710 13:57:35.002166  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 13:57:35.002183  9938 solver.cpp:244]     Train net output #1: loss = 0.082243 (* 1 = 0.082243 loss)
I0710 13:57:35.002192  9938 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0710 13:58:06.395665  9938 solver.cpp:337] Iteration 14000, Testing net (#0)
I0710 13:58:12.055655  9938 solver.cpp:404]     Test net output #0: accuracy = 0.716328
I0710 13:58:12.055713  9938 solver.cpp:404]     Test net output #1: loss = 1.91506 (* 1 = 1.91506 loss)
I0710 13:58:12.164660  9938 solver.cpp:228] Iteration 14000, loss = 0.0682131
I0710 13:58:12.164713  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 13:58:12.164728  9938 solver.cpp:244]     Train net output #1: loss = 0.0682131 (* 1 = 0.0682131 loss)
I0710 13:58:12.164736  9938 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0710 13:58:44.410426  9938 solver.cpp:228] Iteration 14100, loss = 0.0515012
I0710 13:58:44.410568  9938 solver.cpp:244]     Train net output #0: accuracy = 0.980469
I0710 13:58:44.410595  9938 solver.cpp:244]     Train net output #1: loss = 0.0515012 (* 1 = 0.0515012 loss)
I0710 13:58:44.410604  9938 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0710 13:59:16.642524  9938 solver.cpp:228] Iteration 14200, loss = 0.0695947
I0710 13:59:16.642611  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 13:59:16.642627  9938 solver.cpp:244]     Train net output #1: loss = 0.0695947 (* 1 = 0.0695947 loss)
I0710 13:59:16.642635  9938 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0710 13:59:48.879951  9938 solver.cpp:228] Iteration 14300, loss = 0.0820947
I0710 13:59:48.880074  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 13:59:48.880094  9938 solver.cpp:244]     Train net output #1: loss = 0.0820947 (* 1 = 0.0820947 loss)
I0710 13:59:48.880102  9938 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0710 14:00:21.118635  9938 solver.cpp:228] Iteration 14400, loss = 0.0888321
I0710 14:00:21.118808  9938 solver.cpp:244]     Train net output #0: accuracy = 0.960938
I0710 14:00:21.118826  9938 solver.cpp:244]     Train net output #1: loss = 0.0888321 (* 1 = 0.0888321 loss)
I0710 14:00:21.118835  9938 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0710 14:00:52.896559  9938 solver.cpp:228] Iteration 14500, loss = 0.0837009
I0710 14:00:52.896692  9938 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0710 14:00:52.896709  9938 solver.cpp:244]     Train net output #1: loss = 0.0837009 (* 1 = 0.0837009 loss)
I0710 14:00:52.896718  9938 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0710 14:01:24.607275  9938 solver.cpp:228] Iteration 14600, loss = 0.0711598
I0710 14:01:24.607360  9938 solver.cpp:244]     Train net output #0: accuracy = 0.976562
I0710 14:01:24.607378  9938 solver.cpp:244]     Train net output #1: loss = 0.0711598 (* 1 = 0.0711598 loss)
I0710 14:01:24.607385  9938 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0710 14:01:56.316761  9938 solver.cpp:228] Iteration 14700, loss = 0.17474
I0710 14:01:56.316898  9938 solver.cpp:244]     Train net output #0: accuracy = 0.964844
I0710 14:01:56.316915  9938 solver.cpp:244]     Train net output #1: loss = 0.17474 (* 1 = 0.17474 loss)
I0710 14:01:56.316925  9938 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0710 14:02:28.028553  9938 solver.cpp:228] Iteration 14800, loss = 0.082386
I0710 14:02:28.028646  9938 solver.cpp:244]     Train net output #0: accuracy = 0.972656
I0710 14:02:28.028662  9938 solver.cpp:244]     Train net output #1: loss = 0.082386 (* 1 = 0.082386 loss)
I0710 14:02:28.028671  9938 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0710 14:02:59.736616  9938 solver.cpp:228] Iteration 14900, loss = 0.113448
I0710 14:02:59.736701  9938 solver.cpp:244]     Train net output #0: accuracy = 0.957031
I0710 14:02:59.736718  9938 solver.cpp:244]     Train net output #1: loss = 0.113448 (* 1 = 0.113448 loss)
I0710 14:02:59.736726  9938 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0710 14:03:31.134531  9938 solver.cpp:454] Snapshotting to binary proto file snapshots/model2_iter_15000.caffemodel
I0710 14:03:31.508294  9938 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/model2_iter_15000.solverstate
